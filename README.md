# Deep Learning Specialisation on Coursera
Deep Learning Specialisation 2024 by Andrew Ng on Coursera

## Background and objectives
This repo contains workings on Sequence Models application. The following models are implemented

1.- Building your Recurrent Neural Network - Step by Step: implementing key components of a Recurrent Neural Network, or RNN, in NumPy
- Define notation for building sequence models
- Describe the architecture of a basic RNN
- Identify the main components of an LSTMImplement backpropagation through time for a basic RNN and an LSTM
- Give examples of several types of RNN

2.- Character Language Model:build a character-level language model to generate new names
- Store text data for processing using an RNN
- Build a character-level text generation model using an RNN
- Sample novel sequences in an RNN
- Explain the vanishing/exploding gradient problem in RNNs
- Apply gradient clipping as a solution for exploding gradients

3.- Natural Language Processing and Word Embeddings: build an Emojifier by turning images to text
- Create an embedding layer in Keras with pre-trained word vectors
- Explain the advantages and disadvantages of the GloVe algorithm
- Build a sentiment classifier using word embeddings
- Build and train a more sophisticated classifier using an LSTM

4.- Neural Machine Translation: build a Neural Machine Translation (NMT) model to translate human-readable dates ("25th of June, 2009") into machine-readable dates ("2009-06-25")
- The model could be used to translate from one language to another, such as translating from English to Hindi
However, language translation requires massive datasets and usually takes days of training on GPUs. To give you a place to experiment with these models without using massive datasets, we will perform a simpler "date translation" task
- The network learn to output dates in the common machine-readable format YYYY-MM-DD

5.-Sequence Models and Attention Mechanism: applying deep learning to speech recognition
- Structure a speech recognition project
- Synthesize and process audio recordings to create train/dev datasets
- Train a trigger word detection model and make predictions

6.- Long short-term memory (LSTM):implement a model that uses an LSTM to generate music.
- Apply an LSTM to a music generation task
- Generate your own jazz music with deep learning
- Use the flexible Functional API to create complex models


